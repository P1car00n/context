mindmap
  {{"Quality of LLM's Output"}}
    ("SelfCheckGPT")
      ("Faithfulness to the context")
        ("Checks consistency with provided context")
      ("Laconic expression")
        ("Ensures concise and clear answers")
      ("Self-checks for detailed verification")
        ("Internal validation mechanisms")
    ("Cross-examination")
      ("General truthfulness")
        ("Validation against factual data")
      ("Ability to refrain from answering")
        ("Detects and avoids uncertain answers")
      ("Cross-verification by multiple models")
        ("Comparing outputs from different models")
    ("LLM as a Judge")
      ("Alignment with human judgment and preferences")
        ("Evaluates responses based on human feedback")
      ("Judges based on fairness and bias checks")
        ("Assesses potential biases in responses")
    ("RAGAs")
      ("Retrieval-Augmented Generation for context")
        ("Integrates external data sources for context")
      ("Improving accuracy with external data")
        ("Enhances responses with verified data")
    ("Listwise reranking")
      ("Ranks responses based on human preferences")
        ("Prioritizes preferred answers")
      ("Optimizes ranking for best output")
        ("Refines output ranking for quality")
